{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b705f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "dataset_folder = r\"D:\\Code\\Project\\Amazon\\data\"\n",
    "\n",
    "# Load raw data\n",
    "amazon_data = pd.read_csv(os.path.join(dataset_folder, \"amazon_india_complete_2015_2025.csv\"))\n",
    "amazon_data_original = amazon_data.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf145c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class AmazonDataCleaner:\n",
    "    def __init__(self, dataset_folder):\n",
    "        self.dataset_folder = dataset_folder\n",
    "        self.amazon_data = None\n",
    "\n",
    "    # Load Data\n",
    "    def load_data(self):\n",
    "        try:\n",
    "            self.amazon_data = pd.read_csv(\n",
    "                os.path.join(self.dataset_folder, \"amazon_india_complete_2015_2025.csv\")\n",
    "            )\n",
    "            print(f\"Amazon Complete loaded: {self.amazon_data.shape}\")\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            print(\"Please check dataset path.\")\n",
    "\n",
    "# Clean Columns\n",
    "    def clean_columns(self):\n",
    "        # order_date\n",
    "        self.amazon_data['order_date'] = pd.to_datetime(\n",
    "            self.amazon_data['order_date'], \n",
    "            errors='coerce',     # turn bad ones into NaT\n",
    "            dayfirst=True,       # needed for DD-MM-YYYY and DD/MM/YYYY\n",
    "            format=\"mixed\"       # <-- NEW in Pandas 2.0, handles mixed styles\n",
    "        )\n",
    "        self.amazon_data['original_price_inr'] = (\n",
    "            self.amazon_data['original_price_inr'].str.replace(\"Rs\", \"\", regex=False)\n",
    "    .str.replace(\"â‚¹\", \"\", regex=False)   \n",
    "    .str.replace(\"₹\", \"\", regex=False)    \n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    "    .str.replace('-', '', regex=False)\n",
    "    .str.strip()\n",
    "    .astype(float)\n",
    "    .round(2))\n",
    "    # customer_rating\n",
    "        self.amazon_data['customer_rating'] = (\n",
    "            self.amazon_data['customer_rating'].astype(str)\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace('stars', '', regex=False)\n",
    "    .str.replace('star', '', regex=False)\n",
    "\n",
    ")\n",
    "        self.amazon_data['category'] = (\n",
    "            self.amazon_data['category']\n",
    "            .str.strip().str.lower()\n",
    "            .replace({'Electronics': 'Electronics',\n",
    "    'Electronic': 'Electronics',\n",
    "    'ELECTRONICS': 'Electronics',\n",
    "    'Electronics & Accessories': 'Electronics',\n",
    "    'Electronicss': 'Electronics',\n",
    "}   )  )\n",
    "# City Cleaning\n",
    "    def clean_cities(self):\n",
    "        self.amazon_data['customer_city'] = (\n",
    "            self.amazon_data['customer_city'].str.strip().str.lower()\n",
    "        )\n",
    "        city_mapping = {\"kolkata\": \"Kolkata\", \"calcutta\": \"Kolkata\",\n",
    "\n",
    "    \"bangalore\": \"Bengaluru\", \"bengaluru\": \"Bengaluru\",\n",
    "    \"banglore\": \"Bengaluru\", \"bengalore\": \"Bengaluru\",\n",
    "    \"bangalore/bengaluru\": \"Bengaluru\",\n",
    "\n",
    "    \"mumbai\": \"Mumbai\", \"bombay\": \"Mumbai\", \"mumba\": \"Mumbai\",\n",
    "\n",
    "    \"chennai\": \"Chennai\", \"chenai\": \"Chennai\", \"madras\": \"Chennai\",\n",
    "\n",
    "    \"delhi\": \"Delhi\", \"new delhi\": \"Delhi\", \"delhi ncr\": \"Delhi\",\n",
    "\n",
    "    \"kochi\": \"Kochi\", \"ludhiana\": \"Ludhiana\", \"aligarh\": \"Aligarh\",\n",
    "    \"surat\": \"Surat\", \"kanpur\": \"Kanpur\", \"hyderabad\": \"Hyderabad\",\n",
    "    \"bareilly\": \"Bareilly\", \"vadodara\": \"Vadodara\", \"indore\": \"Indore\",\n",
    "    \"visakhapatnam\": \"Visakhapatnam\", \"lucknow\": \"Lucknow\", \"pune\": \"Pune\",\n",
    "    \"bhubaneswar\": \"Bhubaneswar\", \"nagpur\": \"Nagpur\", \"patna\": \"Patna\",\n",
    "    \"ahmedabad\": \"Ahmedabad\", \"jaipur\": \"Jaipur\", \"meerut\": \"Meerut\",\n",
    "    \"varanasi\": \"Varanasi\", \"coimbatore\": \"Coimbatore\",\n",
    "    \"moradabad\": \"Moradabad\", \"saharanpur\": \"Saharanpur\",\n",
    "    \"chandigarh\": \"Chandigarh\", \"gorakhpur\": \"Gorakhpur\",\n",
    "    \"allahabad\": \"Prayagraj\",\n",
    "}\n",
    "\n",
    "        self.amazon_data['customer_city'] = (\n",
    "            self.amazon_data['customer_city']\n",
    "            .map(city_mapping)\n",
    "            .fillna(self.amazon_data['customer_city'])\n",
    "            .str.title()\n",
    "        )\n",
    "    def normalize_booleans(self):\n",
    "      bool_map = {\n",
    "        'true': True, 'yes': True, 'y': True, '1': True,\n",
    "        'false': False, 'no': False, 'n': False, '0': False\n",
    "      }\n",
    "\n",
    "      for col in ['is_festival_sale', 'is_prime_member', 'is_prime_eligible']:\n",
    "        s = (\n",
    "        self.amazon_data[col]\n",
    "            .astype(\"string\")\n",
    "            .str.strip()\n",
    "            .str.lower()\n",
    "        )\n",
    "\n",
    "        self.amazon_data[col] = s.map(bool_map).astype(\"boolean\")\n",
    "\n",
    "# Standardize Customer Rating\n",
    "    def clean_customer_rating(self):\n",
    "      def parse_rating(r):\n",
    "        if pd.isna(r):\n",
    "            return np.nan\n",
    "\n",
    "        r = str(r).strip().lower()\n",
    "\n",
    "        # Handle fraction ratings like 4/5\n",
    "        if '/' in r:\n",
    "            try:\n",
    "                num, den = r.split('/')\n",
    "                return (float(num) / float(den)) * 5\n",
    "            except (ValueError, ZeroDivisionError):\n",
    "                return np.nan\n",
    "\n",
    "        # Handle numeric ratings like \"4.5 stars\"\n",
    "        match = re.search(r'(\\d+(\\.\\d+)?)', r)\n",
    "        if match:\n",
    "            rating = float(match.group(1))\n",
    "            return rating if 0 <= rating <= 5 else np.nan\n",
    "\n",
    "        return np.nan\n",
    "\n",
    "      self.amazon_data['customer_rating'] = (\n",
    "        self.amazon_data['customer_rating']\n",
    "        .apply(parse_rating)\n",
    "    )\n",
    "    # Fill missing ratings by customer_tier mean\n",
    "      self.amazon_data['customer_rating'] = self.amazon_data.groupby('customer_tier')['customer_rating'].transform(\n",
    "        lambda x: x.fillna(x.mean())\n",
    "    )\n",
    "\n",
    "    # Fill any remaining NaN with overall mean\n",
    "      self.amazon_data['customer_rating'] = self.amazon_data['customer_rating'].fillna(\n",
    "        self.amazon_data['customer_rating'].mean()\n",
    "    )\n",
    "\n",
    "    # Round final ratings to 1 decimal\n",
    "      self.amazon_data['customer_rating'] = self.amazon_data['customer_rating'].round(1)\n",
    "    def clean_payment_method(self):\n",
    "        mapping ={\n",
    "    # UPI\n",
    "    'upi': 'UPI',\n",
    "    'phonepe': 'UPI',\n",
    "    'googlepay': 'UPI',\n",
    "    'gpay': 'UPI',\n",
    "\n",
    "    # Credit Card\n",
    "    'credit card': 'Credit Card',\n",
    "    'cc': 'Credit Card',\n",
    "    'credit_card': 'Credit Card',\n",
    "\n",
    "    # Debit Card\n",
    "    'debit card': 'Debit Card',\n",
    "    'dc': 'Debit Card',\n",
    "    # COD\n",
    "    'cash on delivery': 'COD',\n",
    "    'cod': 'COD',\n",
    "    'c.o.d': 'COD',\n",
    "\n",
    "    # Net Banking\n",
    "    'net banking': 'Net Banking',\n",
    "    'netbanking': 'Net Banking',\n",
    "\n",
    "    # Wallet\n",
    "    'wallet': 'Wallet',\n",
    "\n",
    "    # Buy Now Pay Later\n",
    "    'bnpl': 'BNPL'\n",
    "}\n",
    "        \n",
    "        self.amazon_data['payment_method'] = (\n",
    "            self.amazon_data['payment_method']\n",
    "            .astype(str).str.strip().str.lower()\n",
    "            .map(mapping)\n",
    "            .fillna(self.amazon_data['payment_method'].str.title())\n",
    "        )\n",
    "        # Handle Missing Values\n",
    "    def handle_missing_values(self):\n",
    "        # Fill missing delivery_charges with median (to reduce effect of outliers)\n",
    "        self.amazon_data['delivery_charges'] = self.amazon_data['delivery_charges'].fillna(\n",
    "            self.amazon_data['delivery_charges'].median()\n",
    "        )\n",
    "        \n",
    "        # Fill missing customer_age_group with 'Unknown'\n",
    "        self.amazon_data['customer_age_group'] = self.amazon_data['customer_age_group'].fillna('Unknown')\n",
    "        \n",
    "        # Fill missing festival_name based on 'is_festival_sale'\n",
    "        self.amazon_data.loc[\n",
    "            self.amazon_data['is_festival_sale'] == False, \n",
    "            'festival_name'\n",
    "        ] = 'None'\n",
    "        self.amazon_data['festival_name'] = self.amazon_data['festival_name'].fillna('Other')\n",
    "        \n",
    "        # Fill missing customer_rating with average rating per tier (or overall mean)\n",
    "        self.amazon_data['customer_rating'] = self.amazon_data.groupby('customer_tier')['customer_rating'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        # If still some nulls left, fill with overall mean\n",
    "        self.amazon_data['customer_rating'] = self.amazon_data['customer_rating'].fillna(\n",
    "            self.amazon_data['customer_rating'].mean()\n",
    "        )\n",
    "        \n",
    "        print(\"Missing values handled!\")\n",
    "\n",
    "\n",
    "    # Handle Duplicates with Advanced Classification\n",
    "    def handle_duplicates(self, agg_bulk=False):\n",
    "        duplicate_cols = [\n",
    "            'order_date', 'customer_id', 'product_id',\n",
    "            'original_price_inr', 'discounted_price_inr', 'final_amount_inr'\n",
    "        ]\n",
    "        quantity_col = 'quantity'\n",
    "        final_amount_col = 'final_amount_inr'\n",
    "        \n",
    "        # Mark all duplicates\n",
    "        self.amazon_data['is_duplicate'] = self.amazon_data.duplicated(subset=duplicate_cols, keep=False)\n",
    "        \n",
    "        # Group duplicates\n",
    "        grouped = self.amazon_data[self.amazon_data['is_duplicate']].groupby(duplicate_cols)\n",
    "        \n",
    "        # Classify each duplicate group\n",
    "        def classify_duplicate(group):\n",
    "            total_quantity = group[quantity_col].sum()\n",
    "            total_amount = group[final_amount_col].sum()\n",
    "            price_per_unit = group[final_amount_col].iloc[0] / group[quantity_col].iloc[0]\n",
    "            expected_total = total_quantity * price_per_unit\n",
    "            if abs(expected_total - total_amount) < 1e-2:\n",
    "                return \"bulk_order\"\n",
    "            else:\n",
    "                return \"error_duplicate\"\n",
    "        \n",
    "        duplicate_classification = (\n",
    "            grouped.apply(classify_duplicate)\n",
    "            .reset_index(name='duplicate_type')\n",
    "        )\n",
    "        \n",
    "        # Merge back\n",
    "        self.amazon_data = self.amazon_data.merge(duplicate_classification, on=duplicate_cols, how='left')\n",
    "        \n",
    "        # Aggregate bulk orders if needed\n",
    "        if agg_bulk:\n",
    "            bulk_orders = self.amazon_data[self.amazon_data['duplicate_type'] == \"bulk_order\"]\n",
    "            aggregated = bulk_orders.groupby(duplicate_cols, as_index=False).agg({\n",
    "                quantity_col: 'sum',\n",
    "                'subtotal_inr': 'sum',\n",
    "                final_amount_col: 'sum',\n",
    "                'transaction_id': lambda x: ','.join(x)\n",
    "            })\n",
    "            non_bulk = self.amazon_data[self.amazon_data['duplicate_type'] != \"bulk_order\"]\n",
    "            self.amazon_data = pd.concat([non_bulk, aggregated], ignore_index=True)\n",
    "        \n",
    "        return self.amazon_data\n",
    "        # Outlier Detection - IQR Method\n",
    "    def flag_price_outliers_iqr(self):\n",
    "        df = self.amazon_data\n",
    "\n",
    "        q1 = df.groupby(['subcategory', 'brand'])['original_price_inr'].transform('quantile', 0.25)\n",
    "        q3 = df.groupby(['subcategory', 'brand'])['original_price_inr'].transform('quantile', 0.75)\n",
    "\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "\n",
    "        df['price_outlier_IQR'] = (\n",
    "            (df['original_price_inr'] < lower) |\n",
    "            (df['original_price_inr'] > upper)\n",
    "    )\n",
    "        # Flag All Outliers \n",
    "    def flag_outliers(self):\n",
    "        self.flag_price_outliers_iqr()\n",
    "\n",
    "\n",
    "    # Run All Steps\n",
    "    def clean_all(self):\n",
    "        self.load_data()\n",
    "        self.clean_columns()\n",
    "        self.clean_cities()\n",
    "        self.normalize_booleans()\n",
    "        self.clean_customer_rating()\n",
    "        self.clean_payment_method()\n",
    "        self.handle_missing_values()\n",
    "        self.handle_duplicates()\n",
    "        self.flag_outliers()\n",
    "        print(\"Data Cleaning Completed!\")\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f0081da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon Complete loaded: (1127609, 34)\n",
      "Missing values handled!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_47016\\2259502010.py:246: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped.apply(classify_duplicate)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaning Completed!\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1127609 entries, 0 to 1127608\n",
      "Data columns (total 37 columns):\n",
      " #   Column                  Non-Null Count    Dtype         \n",
      "---  ------                  --------------    -----         \n",
      " 0   transaction_id          1127609 non-null  object        \n",
      " 1   order_date              1127609 non-null  datetime64[ns]\n",
      " 2   customer_id             1127609 non-null  object        \n",
      " 3   product_id              1127609 non-null  object        \n",
      " 4   product_name            1127609 non-null  object        \n",
      " 5   category                1127609 non-null  object        \n",
      " 6   subcategory             1127609 non-null  object        \n",
      " 7   brand                   1127609 non-null  object        \n",
      " 8   original_price_inr      1127609 non-null  float64       \n",
      " 9   discount_percent        1127609 non-null  float64       \n",
      " 10  discounted_price_inr    1127609 non-null  float64       \n",
      " 11  quantity                1127609 non-null  int64         \n",
      " 12  subtotal_inr            1127609 non-null  float64       \n",
      " 13  delivery_charges        1127609 non-null  float64       \n",
      " 14  final_amount_inr        1127609 non-null  float64       \n",
      " 15  customer_city           1127609 non-null  object        \n",
      " 16  customer_state          1127609 non-null  object        \n",
      " 17  customer_tier           1127609 non-null  object        \n",
      " 18  customer_spending_tier  1127609 non-null  object        \n",
      " 19  customer_age_group      1127609 non-null  object        \n",
      " 20  payment_method          1127609 non-null  object        \n",
      " 21  delivery_days           1127609 non-null  object        \n",
      " 22  delivery_type           1127609 non-null  object        \n",
      " 23  is_prime_member         1127609 non-null  boolean       \n",
      " 24  is_festival_sale        1127609 non-null  boolean       \n",
      " 25  festival_name           1127609 non-null  object        \n",
      " 26  customer_rating         1127609 non-null  float64       \n",
      " 27  return_status           1127609 non-null  object        \n",
      " 28  order_month             1127609 non-null  int64         \n",
      " 29  order_year              1127609 non-null  int64         \n",
      " 30  order_quarter           1127609 non-null  int64         \n",
      " 31  product_weight_kg       1127609 non-null  float64       \n",
      " 32  is_prime_eligible       1127609 non-null  boolean       \n",
      " 33  product_rating          1127609 non-null  float64       \n",
      " 34  is_duplicate            1127609 non-null  bool          \n",
      " 35  duplicate_type          11086 non-null    object        \n",
      " 36  price_outlier_IQR       1127609 non-null  bool          \n",
      "dtypes: bool(2), boolean(3), datetime64[ns](1), float64(9), int64(4), object(18)\n",
      "memory usage: 283.9+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = r\"D:\\Code\\Project\\Amazon\\data\" \n",
    "cleaner = AmazonDataCleaner(dataset_folder) \n",
    "cleaner.clean_all() \n",
    "amazon_cleaned_data = cleaner.amazon_data \n",
    "amazon_cleaned_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c99075f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to: D:\\Code\\Project\\Amazon\\data\\amazon_india_cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join(dataset_folder, \"amazon_india_cleaned_data.csv\")\n",
    "amazon_cleaned_data.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"Cleaned dataset saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97f1ff8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_count</th>\n",
       "      <th>Original_mean</th>\n",
       "      <th>Original_std</th>\n",
       "      <th>Original_min</th>\n",
       "      <th>Original_25%</th>\n",
       "      <th>Original_50%</th>\n",
       "      <th>Original_75%</th>\n",
       "      <th>Original_max</th>\n",
       "      <th>Cleaned_count</th>\n",
       "      <th>Cleaned_mean</th>\n",
       "      <th>Cleaned_std</th>\n",
       "      <th>Cleaned_min</th>\n",
       "      <th>Cleaned_25%</th>\n",
       "      <th>Cleaned_50%</th>\n",
       "      <th>Cleaned_75%</th>\n",
       "      <th>Cleaned_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>discount_percent</th>\n",
       "      <td>1127609.0</td>\n",
       "      <td>17.420350</td>\n",
       "      <td>20.553770</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.37</td>\n",
       "      <td>28.41</td>\n",
       "      <td>70.00</td>\n",
       "      <td>1127609.0</td>\n",
       "      <td>17.420350</td>\n",
       "      <td>20.553770</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.37</td>\n",
       "      <td>28.41</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discounted_price_inr</th>\n",
       "      <td>1127609.0</td>\n",
       "      <td>54541.339570</td>\n",
       "      <td>45824.804426</td>\n",
       "      <td>344.33</td>\n",
       "      <td>22780.69</td>\n",
       "      <td>38001.19</td>\n",
       "      <td>74103.32</td>\n",
       "      <td>420704.77</td>\n",
       "      <td>1127609.0</td>\n",
       "      <td>54541.339570</td>\n",
       "      <td>45824.804426</td>\n",
       "      <td>344.33</td>\n",
       "      <td>22780.69</td>\n",
       "      <td>38001.19</td>\n",
       "      <td>74103.32</td>\n",
       "      <td>420704.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity</th>\n",
       "      <td>1127609.0</td>\n",
       "      <td>1.250063</td>\n",
       "      <td>0.536503</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1127609.0</td>\n",
       "      <td>1.250063</td>\n",
       "      <td>0.536503</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subtotal_inr</th>\n",
       "      <td>1127609.0</td>\n",
       "      <td>68187.402906</td>\n",
       "      <td>68934.068999</td>\n",
       "      <td>344.33</td>\n",
       "      <td>25217.99</td>\n",
       "      <td>44731.82</td>\n",
       "      <td>88521.79</td>\n",
       "      <td>1262114.31</td>\n",
       "      <td>1127609.0</td>\n",
       "      <td>68187.402906</td>\n",
       "      <td>68934.068999</td>\n",
       "      <td>344.33</td>\n",
       "      <td>25217.99</td>\n",
       "      <td>44731.82</td>\n",
       "      <td>88521.79</td>\n",
       "      <td>1262114.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delivery_charges</th>\n",
       "      <td>1037408.0</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.111078</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>1127609.0</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.106543</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_amount_inr</th>\n",
       "      <td>1127609.0</td>\n",
       "      <td>68187.403225</td>\n",
       "      <td>68934.068685</td>\n",
       "      <td>344.33</td>\n",
       "      <td>25217.99</td>\n",
       "      <td>44731.82</td>\n",
       "      <td>88521.79</td>\n",
       "      <td>1262114.31</td>\n",
       "      <td>1127609.0</td>\n",
       "      <td>68187.403225</td>\n",
       "      <td>68934.068685</td>\n",
       "      <td>344.33</td>\n",
       "      <td>25217.99</td>\n",
       "      <td>44731.82</td>\n",
       "      <td>88521.79</td>\n",
       "      <td>1262114.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_month</th>\n",
       "      <td>1127609.0</td>\n",
       "      <td>6.940627</td>\n",
       "      <td>3.539183</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>1127609.0</td>\n",
       "      <td>6.940627</td>\n",
       "      <td>3.539183</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_year</th>\n",
       "      <td>1127609.0</td>\n",
       "      <td>2020.637254</td>\n",
       "      <td>2.690906</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>2019.00</td>\n",
       "      <td>2021.00</td>\n",
       "      <td>2023.00</td>\n",
       "      <td>2025.00</td>\n",
       "      <td>1127609.0</td>\n",
       "      <td>2020.637254</td>\n",
       "      <td>2.690906</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>2019.00</td>\n",
       "      <td>2021.00</td>\n",
       "      <td>2023.00</td>\n",
       "      <td>2025.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_quarter</th>\n",
       "      <td>1127609.0</td>\n",
       "      <td>2.645922</td>\n",
       "      <td>1.140795</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1127609.0</td>\n",
       "      <td>2.645922</td>\n",
       "      <td>1.140795</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_weight_kg</th>\n",
       "      <td>1127609.0</td>\n",
       "      <td>0.780698</td>\n",
       "      <td>3.674216</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.24</td>\n",
       "      <td>44.26</td>\n",
       "      <td>1127609.0</td>\n",
       "      <td>0.780698</td>\n",
       "      <td>3.674216</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.24</td>\n",
       "      <td>44.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_rating</th>\n",
       "      <td>1127609.0</td>\n",
       "      <td>3.975245</td>\n",
       "      <td>0.453647</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1127609.0</td>\n",
       "      <td>3.975245</td>\n",
       "      <td>0.453647</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Original_count  Original_mean  Original_std  \\\n",
       "discount_percent           1127609.0      17.420350     20.553770   \n",
       "discounted_price_inr       1127609.0   54541.339570  45824.804426   \n",
       "quantity                   1127609.0       1.250063      0.536503   \n",
       "subtotal_inr               1127609.0   68187.402906  68934.068999   \n",
       "delivery_charges           1037408.0       0.000308      0.111078   \n",
       "final_amount_inr           1127609.0   68187.403225  68934.068685   \n",
       "order_month                1127609.0       6.940627      3.539183   \n",
       "order_year                 1127609.0    2020.637254      2.690906   \n",
       "order_quarter              1127609.0       2.645922      1.140795   \n",
       "product_weight_kg          1127609.0       0.780698      3.674216   \n",
       "product_rating             1127609.0       3.975245      0.453647   \n",
       "\n",
       "                      Original_min  Original_25%  Original_50%  Original_75%  \\\n",
       "discount_percent              0.00          0.00         10.37         28.41   \n",
       "discounted_price_inr        344.33      22780.69      38001.19      74103.32   \n",
       "quantity                      1.00          1.00          1.00          1.00   \n",
       "subtotal_inr                344.33      25217.99      44731.82      88521.79   \n",
       "delivery_charges              0.00          0.00          0.00          0.00   \n",
       "final_amount_inr            344.33      25217.99      44731.82      88521.79   \n",
       "order_month                   1.00          4.00          7.00         10.00   \n",
       "order_year                 2015.00       2019.00       2021.00       2023.00   \n",
       "order_quarter                 1.00          2.00          3.00          4.00   \n",
       "product_weight_kg             0.03          0.18          0.21          0.24   \n",
       "product_rating                3.00          3.60          4.00          4.40   \n",
       "\n",
       "                      Original_max  Cleaned_count  Cleaned_mean   Cleaned_std  \\\n",
       "discount_percent             70.00      1127609.0     17.420350     20.553770   \n",
       "discounted_price_inr     420704.77      1127609.0  54541.339570  45824.804426   \n",
       "quantity                      3.00      1127609.0      1.250063      0.536503   \n",
       "subtotal_inr            1262114.31      1127609.0  68187.402906  68934.068999   \n",
       "delivery_charges             40.00      1127609.0      0.000284      0.106543   \n",
       "final_amount_inr        1262114.31      1127609.0  68187.403225  68934.068685   \n",
       "order_month                  12.00      1127609.0      6.940627      3.539183   \n",
       "order_year                 2025.00      1127609.0   2020.637254      2.690906   \n",
       "order_quarter                 4.00      1127609.0      2.645922      1.140795   \n",
       "product_weight_kg            44.26      1127609.0      0.780698      3.674216   \n",
       "product_rating                4.80      1127609.0      3.975245      0.453647   \n",
       "\n",
       "                      Cleaned_min  Cleaned_25%  Cleaned_50%  Cleaned_75%  \\\n",
       "discount_percent             0.00         0.00        10.37        28.41   \n",
       "discounted_price_inr       344.33     22780.69     38001.19     74103.32   \n",
       "quantity                     1.00         1.00         1.00         1.00   \n",
       "subtotal_inr               344.33     25217.99     44731.82     88521.79   \n",
       "delivery_charges             0.00         0.00         0.00         0.00   \n",
       "final_amount_inr           344.33     25217.99     44731.82     88521.79   \n",
       "order_month                  1.00         4.00         7.00        10.00   \n",
       "order_year                2015.00      2019.00      2021.00      2023.00   \n",
       "order_quarter                1.00         2.00         3.00         4.00   \n",
       "product_weight_kg            0.03         0.18         0.21         0.24   \n",
       "product_rating               3.00         3.60         4.00         4.40   \n",
       "\n",
       "                      Cleaned_max  \n",
       "discount_percent            70.00  \n",
       "discounted_price_inr    420704.77  \n",
       "quantity                     3.00  \n",
       "subtotal_inr           1262114.31  \n",
       "delivery_charges            40.00  \n",
       "final_amount_inr       1262114.31  \n",
       "order_month                 12.00  \n",
       "order_year                2025.00  \n",
       "order_quarter                4.00  \n",
       "product_weight_kg           44.26  \n",
       "product_rating               4.80  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = amazon_data_original.select_dtypes(include=np.number).columns\n",
    "\n",
    "summary_comparison = pd.concat(\n",
    "    [\n",
    "        amazon_data_original[numeric_cols].describe().T.add_prefix(\"Original_\"),\n",
    "        amazon_cleaned_data[numeric_cols].describe().T.add_prefix(\"Cleaned_\")\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "summary_comparison\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project-venv)",
   "language": "python",
   "name": "project-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
